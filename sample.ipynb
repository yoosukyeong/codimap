{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy import Spider\n",
    "from scrapy.exporters import CsvItemExporter\n",
    "import csv\n",
    "\n",
    "from .. import items\n",
    "\n",
    "\n",
    "class MusinsaSpider(Spider):\n",
    "\t# 스파이더 이름(실행)\n",
    "    name = \"test\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://www.musinsa.com/categories/item/001004\"\n",
    "        # 상의 - 후드티\n",
    "        yield scrapy.Request(url, self.parse_start)\n",
    "\n",
    "    # 상품 상세 페이지 url로 request\n",
    "    def parse_start(self, response):\n",
    "        product_url = \"https://www.musinsa.com/app/goods/\"\n",
    "        data_no = response.xpath('//li[@class=\"li_box\"]/@data-no').getall()\n",
    "        for d in data_no:\n",
    "            url = product_url + d\n",
    "            yield scrapy.Request(url, self.parse_items)\n",
    "\n",
    "    # 상품 상세 페이지에 있는 정보 크롤링\n",
    "    def parse_items(self, response):\n",
    "        item = items.MusinsaItem()\n",
    "        item['product_name'] = response.xpath('//span[@class=\"product_title\"]/em/text()').get().strip()\n",
    "        item['brand'] = response.xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[1]/p[2]/strong/a/text()').get()\n",
    "        item['product_id'] = response.xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[1]/p[2]/strong/text()')[\n",
    "            1].get().strip()\n",
    "        item['season'] = response.xpath(\n",
    "            '//*[@id=\"product_order_info\"]/div[1]/ul/li[2]/p[2]/strong/text()').get().strip().replace(\" \", \"\")\n",
    "        item['sex'] = response.xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[2]/p[2]/span[2]/span/text()').get()\n",
    "        item['like'] = response.xpath('//*[@id=\"product-top-like\"]/p[2]/span/text()').get()\n",
    "        item['price'] = response.xpath('//*[@id=\"goods_price\"]/del/text()').get()\n",
    "        item['product_img'] = response.xpath('//*[@id=\"bigimg\"]/@src').get()\n",
    "        item['product_info'] = response.xpath('//*[@id=\"detail_view\"]/div[1]/div/img/@src').getall()\n",
    "\n",
    "        yield item\n",
    "\n",
    "    def close(self, reason):\n",
    "        # This method is called when the spider is closed\n",
    "        csv_file = open('musinsa_data_hoodie.csv', 'wb')\n",
    "        csv_exporter = CsvItemExporter(csv_file)\n",
    "        csv_exporter.fields_to_export = ['product_name', 'brand', 'product_id', 'season', 'sex', 'like', 'price', 'product_img', 'product_info']\n",
    "        csv_exporter.start_exporting()\n",
    "\n",
    "        for item in self.parse_items(response=None):\n",
    "            csv_exporter.export_item(item)\n",
    "\n",
    "        csv_exporter.finish_exporting()\n",
    "        csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy import Spider\n",
    "from scrapy.exporters import CsvItemExporter\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from items import MusinsaItem\n",
    "\n",
    "\n",
    "class MusinsaSpider(Spider):\n",
    "    name = \"test\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://www.musinsa.com/categories/item/001004\"\n",
    "        # 상의 - 후드티\n",
    "        yield scrapy.Request(url, self.parse_start)\n",
    "\n",
    "    def parse_start(self, response):\n",
    "        product_url = \"https://www.musinsa.com/app/goods/\"\n",
    "        data_no = response.xpath('//li[@class=\"li_box\"]/@data-no').getall()\n",
    "        \n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode (without UI)\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "        for d in data_no:\n",
    "            url = product_url + d\n",
    "            driver.get(url)\n",
    "            yield scrapy.Request(url, self.parse_items, meta={'driver': driver})\n",
    "\n",
    "    def parse_items(self, response):\n",
    "        driver = response.meta['driver']\n",
    "\n",
    "        item = MusinsaItem()\n",
    "        item['product_name'] = driver.find_element_by_xpath('//span[@class=\"product_title\"]/em').text.strip()\n",
    "        item['brand'] = driver.find_element_by_xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[1]/p[2]/strong/a').text\n",
    "        item['product_id'] = driver.find_element_by_xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[1]/p[2]/strong[2]').text.strip()\n",
    "        item['season'] = driver.find_element_by_xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[2]/p[2]/strong').text.strip().replace(\" \", \"\")\n",
    "        item['sex'] = driver.find_element_by_xpath('//*[@id=\"product_order_info\"]/div[1]/ul/li[2]/p[2]/span[2]/span').text\n",
    "        item['like'] = driver.find_element_by_xpath('//*[@id=\"product-top-like\"]/p[2]/span').text\n",
    "        item['price'] = driver.find_element_by_xpath('//*[@id=\"goods_price\"]/del').text\n",
    "        item['product_img'] = driver.find_element_by_xpath('//*[@id=\"bigimg\"]').get_attribute('src')\n",
    "        item['product_info'] = [img.get_attribute('src') for img in driver.find_elements_by_xpath('//*[@id=\"detail_view\"]/div[1]/div/img')]\n",
    "\n",
    "        yield item"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
